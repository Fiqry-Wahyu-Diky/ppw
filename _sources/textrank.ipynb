{"cells":[{"cell_type":"markdown","metadata":{"id":"hgITV1wORX6Z"},"source":["# Data"]},{"cell_type":"markdown","metadata":{"id":"WHSQYpzuQWNx"},"source":["## EDA (Explorasi Data Analysis)  \n","> proses analisis awal yang dilakukan pada dataset untuk memahami karakteristik, pola, dan struktur data sebelum melakukan analisis lebih lanjut atau membangun model."]},{"cell_type":"markdown","metadata":{"id":"_OeknmGhQYms"},"source":["### Download dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cLkq2iRPMnTe"},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","import gdown\n","import string"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MUBsb243N9Ut"},"outputs":[],"source":["name = 'data_crawling_berita_antaranews.csv'\n","gdown.download(f'https://drive.google.com/uc?id=1iuY-raVaRjcwV63Ua8fIGa9dC01yvPvQ', name, quiet=False)"]},{"cell_type":"markdown","metadata":{"id":"8u926-w3Qcef"},"source":["### Baca dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1kVya2aOPGpf"},"outputs":[],"source":["data = pd.read_csv(\"data_crawling_berita_antaranews.csv\")\n","data"]},{"cell_type":"markdown","metadata":{"id":"_mUOZ1VSQfnU"},"source":["#### Banyak dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iOKw-7rnQhWT"},"outputs":[],"source":["len(data)"]},{"cell_type":"markdown","metadata":{"id":"5JfMvXRyQksG"},"source":["#### Banyak dataset setiap kelas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aUDhCOHxQlgG"},"outputs":[],"source":["count_ekonomi = 0\n","count_olahraga= 0\n","count_politik = 0\n","\n","for value in data['Label']:\n","  if value == 'ekonomi':\n","    count_ekonomi+=1\n","  elif value == 'olahraga':\n","    count_olahraga+=1\n","  else:\n","    count_politik += 1\n","\n","print(\n","f'''\n","Banyak data ekonomi = {count_ekonomi} data\n","Banyak data olahraga= {count_olahraga} data\n","Banyak data politik = {count_politik} data\n","\n","Total Data          = {len(data)} data\n","'''\n",")"]},{"cell_type":"markdown","metadata":{"id":"-qowd8zCRd89"},"source":["## Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"1k7XLeBsRf60"},"source":["### Missing Value  \n","> merupakan nilai pada sebuah data yang kosong/none sehingga harus dihapus untuk proses lebih lanjut"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x2a21gbaPOWD"},"outputs":[],"source":["data = data.dropna()\n","data"]},{"cell_type":"markdown","metadata":{"id":"tiOyIOPaRmEc"},"source":["### Duplicate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F13N3bbEPV4R"},"outputs":[],"source":["data.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ALio1mbnPXs9"},"outputs":[],"source":["data = data.drop_duplicates()\n","data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tbgTS_k5Pi_5"},"outputs":[],"source":["data.reset_index(drop=True, inplace=True) #atur indeks data mulai dari 0 lagi"]},{"cell_type":"markdown","metadata":{"id":"QdQqXO13Rpi5"},"source":["### **Punctuation process**\n","\n","> **Punctuation process** merupakan proses normalisasi data yang bertujuan untuk menghilangkan tanda baca\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGRuAcTbPklr"},"outputs":[],"source":["import re\n","data['clean_artikel'] = data['Artikel'].str.replace(r'[^\\w\\s,.?!]', '', regex=True).str.lower()\n","\n","# Menghilangkan angka dari kolom 'new_abstrak'\n","data['clean_artikel'] = data['clean_artikel'].str.replace('\\d+', '', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4jQ0XpmeP-UE"},"outputs":[],"source":["data"]},{"cell_type":"markdown","metadata":{"id":"_0pZ5YAARNEs"},"source":["### **Stopword**\n","\n","> Stopwords digunakan untuk menghilangkan kata umum yang sering muncul dalam teks seperti: di, dan, atau, dari, ke, saya.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QuZ42ZWpRN_l"},"outputs":[],"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.corpus import stopwords\n","import nltk\n","nltk.download('punkt')\n","\n","# Download kamus stop words\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tLNDG74KROiM"},"outputs":[],"source":["# Inisialisasi kamus stop words dari NLTK\n","stop_words = set(stopwords.words('indonesian'))  # Inisialisasi kamus stop words\n","\n","# Menghapus stop words dari kolom 'Abstrak'\n","for stop_word in stop_words:\n","  data['artikel_stopword'] = data['clean_artikel'].str.replace(rf'\\b{stop_word}\\b', '', regex=True) #rf untuk formating string"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tf-iMtqjP_m4"},"outputs":[],"source":["data"]},{"cell_type":"markdown","metadata":{"id":"NqHad843SJdR"},"source":["### Tokenizing  \n","\n","> **Tokenizing** adalah proses memecah teks atau dokumen menjadi potongan-potongan yang lebih kecil, yang disebut token. Disini menggunakan term kalimat"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XHCKic-LQP7_"},"outputs":[],"source":["data[\"tokenizing\"] = data['artikel_stopword'].apply(sent_tokenize)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k17hP6BZQclv"},"outputs":[],"source":["data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yxBuHd3RSExI"},"outputs":[],"source":["len(data['tokenizing'][0])"]},{"cell_type":"markdown","metadata":{"id":"j0l_BOVMegdS"},"source":["## VSM"]},{"cell_type":"markdown","metadata":{"id":"rIRXWHcxQ-C4"},"source":["### Term Freq\n","\n","> Term Freq adalah konsep yang digunakan dalam pemrosesan teks dan analisis teks untuk mengukur sejauh mana suatu kata atau term muncul dalam sebuah dokumen atau koleksi dokumen. Term frequency menggambarkan seberapa sering sebuah kata muncul dalam teks relatif terhadap total kata dalam dokumen tersebut.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nwd3qexiQ-sf"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I1SRHsMXRoFI"},"outputs":[],"source":["hasil_df_tf = []\n","set_len_doc = data['tokenizing']\n","\n","for i in range(len(set_len_doc)): #perulangan setiap artikel/dokumen\n","  termFreq_vectorizer = CountVectorizer()  #inisialisasi tfidf\n","\n","  termFreq_matrix = termFreq_vectorizer.fit_transform(data['tokenizing'][i]) #menjadikan tfidf setiap dokumen\n","  terms = termFreq_vectorizer.get_feature_names_out() #ambil nama fitur\n","\n","  tf_df = pd.DataFrame(termFreq_matrix.toarray(), columns=terms) #menjadikan dataframe\n","  hasil_df_tf.append(tf_df) #menyimpan dalam variabel df_tf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WAXNb5iqTO0V"},"outputs":[],"source":["# menampilkan hasil banyak kata pada kalimat\n","\n","for i in range(len(hasil_df_tf[:10])):\n","  show_df = hasil_df_tf[i]\n","  print(f\"========= Dokumen ke - {i} ==============\")\n","  display(show_df)\n","  print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"3W5Pyo8DT0vN"},"source":["## Co-occurrence metrics  \n","> merupakan metrik kemunculan bersama merujuk pada ukuran-ukuran atau metode-metode yang digunakan untuk mengukur sejauh mana dua atau lebih elemen muncul bersama-sama dalam sebuah dataset. Ini dapat diterapkan dalam berbagai konteks, tergantung pada jenis data dan tujuan analisisnya. Berikut adalah beberapa contoh metrik kemunculan bersama yang umum digunakan:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i7jpU8b-eR97"},"outputs":[],"source":["hasil_co_occurrence_df = [] #untuk menyimpan dataframe co-occurance\n","hasil_co_occurrence_matrix = [] #menyimpan hasil matrixnya\n","\n","for i in range(len(hasil_df_tf)):\n","  # Membuat Co-occurrence Matrix\n","  co_occurrence_matrix = np.dot(hasil_df_tf[i].T,hasil_df_tf[i])\n","\n","  # Mengganti diagonal dengan nol (karena kita tidak ingin memperhitungkan kata dengan dirinya sendiri)\n","  np.fill_diagonal(co_occurrence_matrix, 0)\n","\n","  # mengambil columns\n","  kolom = hasil_df_tf[i].columns\n","\n","  # # Membuat DataFrame Co-occurrence\n","  co_occurrence_df = pd.DataFrame(co_occurrence_matrix, index=kolom, columns=kolom)\n","\n","  hasil_co_occurrence_df.append(co_occurrence_df) #simpan dataframe\n","  hasil_co_occurrence_matrix.append(co_occurrence_matrix) #simpan hasil matrix\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WW5l2LNChwkM"},"outputs":[],"source":["#menampilkan hasil co-occurence\n","\n","for i in range(len(hasil_co_occurrence_df[:10])):\n","  print(f\"============== Dokumen ke - {i} ==============\")\n","  display(hasil_co_occurrence_df[i])\n","  print('\\n')"]},{"cell_type":"markdown","metadata":{"id":"Y8_9zelOiLNK"},"source":["## Tambahkan ke graf dan beri treshold"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1cZRel2oiNta"},"outputs":[],"source":["import networkx as nx\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KR9JYNRIieHe"},"outputs":[],"source":["graf_results = []\n","treshold = 0\n","\n","for i in range(len(hasil_co_occurrence_df)):\n","\n","  graf = nx.Graph()  # Instantiate as a Graph object\n","\n","  co_occurrence = hasil_co_occurrence_df[i] #mengambil hasil coocurence per indeks yang disimpan array\n","  koloms = co_occurrence.columns #mengambil nama kolom saja dari coocurence array indeks\n","  matrix_coocurrence = hasil_co_occurrence_matrix[i] #mengambil matrix coocurencenya\n","\n","  for i_koloms in range(len(koloms)): #perulangan setiap dari panjang kolom dari coocurence\n","      for j_koloms in range(i_koloms + 1, len(koloms)): #perulangan dari setiap panjang kolom + 1, maksudna kolom indeks ke dua\n","        bobot = matrix_coocurrence[i_koloms,j_koloms] #mencari bobot dengan setiap kolom\n","\n","        if bobot > treshold: #cek apakah bobot lebih dari treshold\n","          graf.add_edge(koloms[i_koloms], koloms[j_koloms], weight=matrix_coocurrence[i_koloms, j_koloms])\n","\n","  graf_results.append(graf)\n"]},{"cell_type":"code","source":["# hasil_co_occurrence_df[:1]"],"metadata":{"id":"A_CnMbl62tqo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Menetapkan treshold\n","# treshold = 0\n","\n","# # Inisialisasi list untuk menyimpan hasil graf\n","# graf_results = []\n","\n","# # Iterasi melalui setiap DataFrame dalam list\n","# for i in range(len(hasil_co_occurrence_df)):\n","#   # Iterasi melalui setiap kolom DataFrame\n","#   for j in range(len(hasil_co_occurrence_df[i].columns)):\n","#       # Membuat graf hanya untuk nilai di atas treshold\n","#       edges_above_threshold = hasil_co_occurrence_df[i][hasil_co_occurrence_df[i][hasil_co_occurrence_df[i].columns[j]] > treshold].index.tolist()\n","#       G = nx.from_pandas_adjacency(hasil_co_occurrence_df[i].loc[edges_above_threshold, edges_above_threshold])\n","\n","#       # Menambahkan graf ke list hasil\n","#       graf_results.append(G)\n"],"metadata":{"id":"toQvTiGtxrQa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(graf_results)"],"metadata":{"id":"SgWLZ66Ayp9a"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ZzBMdqtobrt"},"outputs":[],"source":["# menampilkan graf\n","\n","for i in range(len(graf_results[:3])):\n","  pos = nx.spring_layout(graf_results[i])  ## Menentukan posisi/koordinat simpul\n","  labels = nx.get_edge_attributes(graf_results[i], 'weight') ##mendapatkan atribut berbobot ('weight') dari setiap sisi dalam graf.\n","\n","  # Menentukan ukuran canvas\n","  plt.figure(figsize=(50, 30))\n","\n","  # Menggambar graf dengan ukuran canvas yang diperbesar\n","  nx.draw(graf_results[i], pos, with_labels=True, node_size=2000, node_color='skyblue')\n","  nx.draw_networkx_edge_labels(graf_results[i], pos, edge_labels=labels, font_color='red')\n","  print(f\"====== Dokumen ke - {i} ===========\")\n","  plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"3ptYMUb3PIul"},"source":["## Hitung Centrality"]},{"cell_type":"markdown","source":["#### Pagerank\n","> Perhitungan manual  \n","> Algoritma (Rumus)  \n","> Perbandingan hasil manual dan library  "],"metadata":{"id":"J0kIzxIQVInz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lpOIYrHPmxkg"},"outputs":[],"source":["centrality_result = []\n","\n","for i in range(len(graf_results)):\n","\n","  centrality = nx.pagerank(graf_results[i]) #menjadikan graf setiap index list diclosness\n","\n","  centrality_result.append(centrality) #menyimpan hasil centrality\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"roJblryuPYI9"},"outputs":[],"source":["# menampilkan centrality\n","for i in range(len(centrality_result[:5])):\n","  print(f\"================== Dokumen ke - {i} ==================\")\n","  print(f\"Text rank score : {centrality_result[i]}\")"]},{"cell_type":"markdown","source":["#### Ranking kata kunci"],"metadata":{"id":"eAllenzDMza-"}},{"cell_type":"code","source":["sorted_closeness_all = []\n","for i in range(len(centrality_result)):\n","  sorted_closeness = dict(sorted(centrality_result[i].items(), key=lambda item: item[1], reverse=True))\n","  sorted_closeness_all.append(sorted_closeness)\n","\n","sorted_closeness_all[2]"],"metadata":{"id":"gNvW3KIeM1HB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#kalimat tertinggi\n","\n","kalimat_tertinggi_all = []\n","\n","for i in range(len(sorted_closeness_all)):\n","    kalimat_tertinggi = []\n","    for j in range(5):\n","        max_key = None\n","        max_value = None\n","\n","        for key, value in sorted_closeness_all[i].items():\n","            if key not in kalimat_tertinggi and (max_value is None or value > max_value):\n","                max_key = key\n","                max_value = value\n","\n","        if max_key is not None:\n","            kalimat_tertinggi.append(max_key)\n","\n","    kalimat_tertinggi_all.append(kalimat_tertinggi)"],"metadata":{"id":"j65OF7F8M9vh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(kalimat_tertinggi_all[0])"],"metadata":{"id":"WVXntUzrNx_C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(kalimat_tertinggi_all[:10])):\n","  print(f\"====== Dokumen ke-{i} =====\")\n","  print(f'Kata kunci : {kalimat_tertinggi_all[i]}')\n","  print('\\n')"],"metadata":{"id":"9faxhYt-NAQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FgJUKqQIvoUX"},"outputs":[],"source":["# hc = nx.pagerank(graf_results[0])\n","# hc = dict(sorted(hc.items(), key=lambda item: item[1], reverse=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LV3SBYzT7WDA"},"outputs":[],"source":["# hc = nx.pagerank(graf_results[0])\n","# hc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3tDRzLuX3sRh"},"outputs":[],"source":["# wordss = []\n","# for i in data['tokenizing'][0]:\n","#   wordss.append(i.split())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n4vALqTR6-bg"},"outputs":[],"source":["# # Inisialisasi kamus untuk menyimpan skor\n","# skor_wordss = {}\n","\n","# # Loop untuk setiap kata di wordss[0]\n","# for kata in wordss[2]:\n","#     # print('word : ',kata)\n","#     # Jika kata ada di var1, ambil skornya; jika tidak, set skor menjadi 0\n","#     if kata in hc:\n","#         skor_wordss[kata] = hc[kata]\n","#         print('hc:',hc[kata])\n","#     else:\n","#         skor_wordss[kata] = 0\n","\n","# # print(skor_wordss)"]},{"cell_type":"code","source":["centrality_result[0]"],"metadata":{"id":"YSvTixG-ifzp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['tokenizing'][0]"],"metadata":{"id":"aB6GLtNBDxcp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J3adxNIYrdZs"},"source":["## Meranking kata sesuai kalimat artikel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-jlwbbsgQz_Q"},"outputs":[],"source":["result_skor = []\n","\n","for i_c in range(len(centrality_result)): #perulangan setiap hasil centrality\n","  current_skor = [] #untuk menyimpan skor sementara\n","\n","  for sentences in data['tokenizing'][i_c]: #perulangan kalimat pada data dalam kolom tokenize\n","    skor_kata = {} #untuk menyimpan skor kata sementara\n","\n","    words = sentences.split() #menjadikan kalimat berupa kata\n","    pin_centrality = centrality_result[i_c] #assign centrality indeks sekarang 1,2,3,4...\n","    panjang_words = len(words) #panjang kata\n","\n","    for hasil_word in words:\n","\n","      if hasil_word in pin_centrality:\n","        skor_kata[hasil_word] = pin_centrality[hasil_word]\n","\n","      else:\n","        skor_kata[hasil_word] = 0\n","    current_skor.append(skor_kata)\n","  result_skor.append(current_skor)\n"]},{"cell_type":"code","source":["result_skor[0]"],"metadata":{"id":"Ibf-2MaOKYCC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_skor[0]"],"metadata":{"id":"6WjMCLZoLXww"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CBqA-AyDYwTX"},"outputs":[],"source":["result_bobot_kalimat = []\n","\n","for i in range(len(result_skor)): #perulangan result skor\n","  current_bobot = {} #untuk menyimpan hasil kalimat dan bobotnya\n","\n","  for j in range(len(result_skor[i])):\n","    bobot_kalimat = sum(result_skor[i][j].values())\n","    current_bobot[data['tokenizing'][i][j]] = bobot_kalimat\n","\n","  result_bobot_kalimat.append(current_bobot)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9zgvf2WzjZaM"},"outputs":[],"source":["# result_bobot_kalimat"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6tACpGoai3z9"},"outputs":[],"source":["final_kalimat = []\n","\n","for i in range(len(result_bobot_kalimat)):\n","  # Mengurutkan dictionary berdasarkan nilai (dari besar ke kecil)\n","  sorted_data = dict(sorted(result_bobot_kalimat[i].items(), key=lambda item: item[1], reverse=True))\n","\n","  # Mengambil 5 nilai teratas beserta key-nya\n","  top_5_keys = {k: sorted_data[k] for k in list(sorted_data)[:5]}\n","\n","  # Menggabungkan key menjadi satu string\n","  result_string = ' '.join(top_5_keys)\n","\n","  final_kalimat.append(result_string)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JBB9VFn1oaLI"},"outputs":[],"source":["# tampilkan\n","for i in range(len(final_kalimat)):\n","  print(f'===== Dokumen {i} ======')\n","  print(final_kalimat[i])\n","  print('\\n')"]},{"cell_type":"markdown","source":["### Save"],"metadata":{"id":"2ttSvD8wMTXa"}},{"cell_type":"code","source":["datas = []\n","for i in range(len(final_kalimat)):\n","  datas.append({\n","      'Summary' : final_kalimat[i],\n","      'Label' : data['Label'][i]\n","  })"],"metadata":{"id":"miRsnKktMVKP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zT5BRU9LrfNm"},"outputs":[],"source":["import csv\n","# Menyimpan data dalam bentuk CSV\n","csv_filename = 'data_textrank_antaranews.csv'\n","with open(csv_filename, 'w', newline='', encoding='utf-8') as csv_file:\n","    fieldnames = ['Summary', 'Label']\n","    csv_writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n","    csv_writer.writeheader()\n","\n","    for entry in datas:\n","        csv_writer.writerow(entry)\n","\n","print(f\"Data telah disimpan dalam file {csv_filename}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfxupkxdiWtT"},"outputs":[],"source":["textrank = pd.read_csv('data_textrank_antaranews.csv')\n","textrank"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vNwlRMUhfGFH"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"MOY8QdtnDSVY"},"source":["## Ex sentence tfidf, coocurence, graf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6xRmBf5T7fA"},"outputs":[],"source":["from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","from networkx.algorithms.shortest_paths import weighted"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03g8P7JQDVov"},"outputs":[],"source":["x = ['saya pergi ke pasar','saya makan nasi','saya naik sepeda']\n","# x = [['saya pergi ke pasar'],['saya makan nasi'],['saya naik sepeda']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35TWgQXyUTwN"},"outputs":[],"source":["x[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qg_A_kZYarMH"},"outputs":[],"source":["# Inisialisasi CountVectorizer\n","vectorizer = CountVectorizer()\n","\n","# Melakukan transformasi TF pada kolom 'final_abstrak'\n","ex_tf_matrix = vectorizer.fit_transform(x)\n","terms = vectorizer.get_feature_names_out()\n","# Membuat DataFrame dari hasil TF\n","ex_tf_df = pd.DataFrame(ex_tf_matrix.toarray(), columns=terms)\n","\n","# Cetak DataFrame TF\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XjkutD7ZVaN2"},"outputs":[],"source":["ex_tf_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuWHp1d2YiAG"},"outputs":[],"source":["# Membuat Co-occurrence Matrix\n","ex_co_occurrence_matrix = np.dot(ex_tf_df.T, ex_tf_df)\n","\n","# Konversi ke dense matrix\n","# ex_co_occurrence_matrix = ex_co_occurrence_matrix.toarray()\n","\n","# Mengganti diagonal dengan nol (karena kita tidak ingin memperhitungkan kata dengan dirinya sendiri)\n","np.fill_diagonal(ex_co_occurrence_matrix, 0)\n","\n","# # Membuat DataFrame Co-occurrence\n","ex_co_occurrence_df = pd.DataFrame(ex_co_occurrence_matrix, index=terms, columns=terms)\n","\n","# # Tampilkan DataFrame Co-occurrence\n","# print(\"Co-occurrence Matrix:\")\n","ex_co_occurrence_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HLXkuD3NkYoP"},"outputs":[],"source":["ex_co_occurrence_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s9KzKbeGkr2h"},"outputs":[],"source":["terms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ain41tZafgjJ"},"outputs":[],"source":["u = hasil_df_tf[0]\n","v = u.T.dot(u)\n","v"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7j7ykb5KgM-h"},"outputs":[],"source":["v.values[(np.r_[:len(v)], ) * 2] = 0\n","v"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9DJmZD6es0pI"},"outputs":[],"source":["import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","# Membuat graf dari matriks co-occurrence\n","graf_result_coba = nx.from_pandas_adjacency(ex_co_occurrence_df)\n","\n","# # Menambahkan edge dan weight dari matriks co-occurrence\n","# for i in range(len(terms)):\n","#     for j in range(i + 1, len(terms)):\n","#         if co_occurrence_matrix[i, j] > 0:\n","#             graf_result_coba.add_edge(terms[i], terms[j], weight=co_occurrence_matrix[i, j])\n","\n","# # Menyiapkan posisi node untuk tampilan yang baik\n","# pos = nx.spring_layout(graf_result_coba)\n","\n","# Menggambar graf\n","nx.draw(graf_result_coba, pos, with_labels=True, font_weight='bold', node_size=700, node_color='skyblue', font_size=8)\n","\n","# Menambahkan label weight pada setiap edge\n","edge_labels = nx.get_edge_attributes(graf_result_coba, 'weight')\n","nx.draw_networkx_edge_labels(graf_result_coba, pos, edge_labels=edge_labels)\n","\n","# Menampilkan graf\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g1KSUhMUDF40"},"outputs":[],"source":["# Cuma cek Hitung closeness centrality pada index 0\n","closeness_centrality_coba = nx.pagerank(graf_result_coba)\n","closeness_centrality_coba"]},{"cell_type":"code","source":["rankingcoba = dict(sorted(closeness_centrality_coba.items(), key=lambda item: item[1], reverse=True))\n","rankingcoba"],"metadata":{"id":"yeBXQn_qGAeL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9NLqtDTsYqDa"},"outputs":[],"source":["# Cuma cek Hitung closeness centrality pada index 0\n","closeness_centrality_coba2 = nx.closeness_centrality(graf_result_coba)\n","closeness_centrality_coba2"]},{"cell_type":"code","source":["rankingcoba2 = dict(sorted(closeness_centrality_coba.items(), key=lambda item: item[1], reverse=True))\n","rankingcoba2"],"metadata":{"id":"mEiRJUMRGa0o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modeling"],"metadata":{"id":"nA2uA2cKZaDI"}},{"cell_type":"markdown","source":["## EDA (Explorasi Data Analysis)  \n","> proses analisis awal yang dilakukan pada dataset untuk memahami karakteristik, pola, dan struktur data sebelum melakukan analisis lebih lanjut atau membangun model."],"metadata":{"id":"tEr12fFBZymY"}},{"cell_type":"markdown","source":["### 1.Download dataset"],"metadata":{"id":"Hc0el3zyZ03V"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import gdown"],"metadata":{"id":"wXLc_txHZce3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-dNiyeL6c83q"},"outputs":[],"source":["## download data\n","nama_data = 'datatextrank.csv'\n","gdown.download(f'https://drive.google.com/uc?id=1eSvQ-SREetN-UkUblym3tYshrOjSvCAM', nama_data, quiet=False)"]},{"cell_type":"markdown","source":["### 2.Baca dataset"],"metadata":{"id":"q8Vjep3LaLbh"}},{"cell_type":"code","source":["datatextrank = pd.read_csv(\"datatextrank.csv\")\n","datatextrank"],"metadata":{"id":"w1WL8BkJaOE4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Banyak dataset"],"metadata":{"id":"QMcqYbs-aTQV"}},{"cell_type":"code","source":["count_ekonomi = 0\n","count_olahraga= 0\n","count_politik = 0\n","\n","for value in datatextrank['Label']:\n","  if value == 'ekonomi':\n","    count_ekonomi+=1\n","  elif value == 'olahraga':\n","    count_olahraga+=1\n","  else:\n","    count_politik += 1\n","\n","print(\n","f'''\n","Banyak data ekonomi = {count_ekonomi} data\n","Banyak data olahraga= {count_olahraga} data\n","Banyak data politik = {count_politik} data\n","\n","Total Data          = {len(datatextrank)} data\n","'''\n",")"],"metadata":{"id":"n0RaruaSaSDM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Preprocessing"],"metadata":{"id":"F4iQRoWfab9R"}},{"cell_type":"code","source":["### 1.Missing value\n","datatextrank.isna().sum()"],"metadata":{"id":"rdJ2-OxJae1s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Cleaning"],"metadata":{"id":"cLEmRh37amkX"}},{"cell_type":"code","source":["# recruitments punctuation\n","import string\n","\n","# membuat kolom baru dengan nama new_abstrak untuk data baru yang dipunctuation\n","datatextrank['summary_punct'] = datatextrank['Summary'].str.replace('[{}]'.format(string.punctuation), '').str.lower()\n","\n","# Menghilangkan angka dari kolom 'new_abstrak'\n","datatextrank['summary_punct'] = datatextrank['summary_punct'].str.replace('\\d+', '', regex=True)"],"metadata":{"id":"IQRLoT-QansE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datatextrank"],"metadata":{"id":"TTUL46daayQd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Stopword**\n","\n","> Stopwords digunakan untuk menghilangkan kata umum yang sering muncul dalam teks seperti: di, dan, atau, dari, ke, saya."],"metadata":{"id":"0c3rRCA1a_Eg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"AptZlEVcduhF"},"outputs":[],"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from nltk.corpus import stopwords\n","import nltk\n","nltk.download('punkt')\n","\n","# Download kamus stop words\n","nltk.download('stopwords')"]},{"cell_type":"code","source":["# Inisialisasi kamus stop words dari NLTK\n","stop_words = set(stopwords.words('indonesian'))  # Inisialisasi kamus stop words\n","\n","# Menghapus stop words dari kolom 'Abstrak'\n","for stop_word in stop_words:\n","  datatextrank['summary_stopwords'] = datatextrank['summary_punct'].str.replace(rf'\\b{stop_word}\\b', '', regex=True) #rf untuk formating string"],"metadata":{"id":"_HSTi1fybBpx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datatextrank"],"metadata":{"id":"-71u4jt9udMs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### TFIDF  \n","> metode yang digunakan dalam pemrosesan bahasa alami (Natural Language Processing - NLP) dan pengambilan informasi (Information Retrieval) untuk mengukur seberapa penting suatu kata dalam suatu dokumen atau kumpulan dokumen. Tujuannya adalah untuk memberikan bobot yang lebih tinggi kepada kata-kata yang penting dalam representasi teks."],"metadata":{"id":"bisgISsCbNaW"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","# Inisialisasi TfidfVectorizer\n","summ_tfidf_vectorizer = TfidfVectorizer()\n","\n","# Melakukan transformasi TF-IDF pada kolom 'final_abstrak'\n","summ_tfidf_matrix = summ_tfidf_vectorizer.fit_transform(datatextrank['summary_stopwords'])\n","\n","# Membuat DataFrame dari hasil TF-IDF\n","summ_tfidf_df = pd.DataFrame(summ_tfidf_matrix.toarray(),columns=summ_tfidf_vectorizer.get_feature_names_out())\n","\n","summ_tfidf_df = pd.concat([datatextrank['Summary'],summ_tfidf_df,datatextrank['Label']],axis=1)\n","# Cetak DataFrame TF-IDF\n","summ_tfidf_df"],"metadata":{"id":"sBfUX01mbDk4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pd.DataFrame(summ_tfidf_df['Summary'])"],"metadata":{"id":"4S5TTVCrknV8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# summ_tfidf_df.iloc[:,1:-1]"],"metadata":{"id":"Pt0wfF9Pqhuc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model"],"metadata":{"id":"4lF-h8iUbZ23"}},{"cell_type":"markdown","source":["#### Split dataset"],"metadata":{"id":"LWwewrS4bckV"}},{"cell_type":"code","source":["# import library\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"KS-JKv7SbeXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Bagi data menjadi pelatihan (80%) dan pengujian (20%)\n","X_tfidf = summ_tfidf_matrix\n","# X_tfidf\n","y_tfidf = summ_tfidf_df[\"Label\"]\n","# y_tfidf\n","X_tfidf_train, X_tfidf_test, y_tfidf_train, y_tfidf_test = train_test_split(X_tfidf, y_tfidf, test_size=0.2, random_state=42)\n"],"metadata":{"id":"JEP8SfD6bfzg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(X_tfidf_train.toarray())\n","len(y_tfidf_train)"],"metadata":{"id":"-5fG5hnugbfp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(len(y_tfidf_test),len(X_tfidf_test))"],"metadata":{"id":"PPNET6gGqu6T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_tfidf_train.info()"],"metadata":{"id":"KDG2xXWgqzxD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Naive Bayes"],"metadata":{"id":"zvmT5g99biL9"}},{"cell_type":"code","source":["#Metrics\n","from sklearn.metrics import make_scorer, accuracy_score,precision_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score ,precision_score,recall_score,f1_score\n","from sklearn.preprocessing import LabelEncoder\n","\n","from sklearn.naive_bayes import GaussianNB"],"metadata":{"id":"XU0nWGT_bi1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.naive_bayes import GaussianNB\n","\n","# Contoh penggunaan\n","naive_bayes = GaussianNB()\n","\n","# Konversi matriks sejumput ke matriks padat untuk data pelatihan\n","X_dense_train = X_tfidf_train.toarray()\n","naive_bayes.fit(X_dense_train, y_tfidf_train)\n","\n","# Konversi matriks sejumput ke matriks padat untuk data pengujian\n","X_dense_test = X_tfidf_test.toarray()\n","y_pred = naive_bayes.predict(X_dense_test)\n","\n","accuracy_naiveBayes = accuracy_score(y_tfidf_test, y_pred)\n","print(f'Akurasi model Naive Bayes: {accuracy_naiveBayes}')"],"metadata":{"id":"6tjacA2Lbknr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### KNN"],"metadata":{"id":"D81boQiKborp"}},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier"],"metadata":{"id":"7md_kuBubm_p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["knn = KNeighborsClassifier()\n","\n","X_dense_train = X_tfidf_train.toarray()\n","\n","# Latih model pada kolom topik tertentu\n","knn.fit(X_dense_train, y_tfidf_train)\n","\n","# Lakukan prediksi\n","y_pred = knn.predict(X_tfidf_test)\n","\n","accuracy_knn = accuracy_score(y_tfidf_test, y_pred)\n","print(f'Akurasi model KNN: {accuracy_knn}')"],"metadata":{"id":"MMQBiZtJbqTH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Random Forest"],"metadata":{"id":"j-GvJgsRbsob"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier"],"metadata":{"id":"A9gdm98abu45"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Inisialisasi model Naive Bayes\n","rf = RandomForestClassifier()\n","\n","X_dense_train = X_tfidf_train.toarray()\n","\n","# Latih model pada kolom topik tertentu\n","rf.fit(X_dense_train, y_tfidf_train)\n","\n","# Lakukan prediksi\n","y_pred = rf.predict(X_tfidf_test)\n","\n","accuracy_rf = accuracy_score(y_tfidf_test, y_pred)\n","print(f'Akurasi model Random Forest: {accuracy_rf}')"],"metadata":{"id":"4IRITEEubwRO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluasi"],"metadata":{"id":"EpjQxTbzbxw3"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","models = ['Naive Bayes', 'KNN', 'Random Forest']\n","accuracies = [accuracy_naiveBayes, accuracy_knn, accuracy_rf]\n","\n","plt.bar(models, accuracies, color=[ 'green', 'blue', 'red'])\n","plt.ylabel('Akurasi Model')\n","plt.title('Akurasi Model Machine Learning')\n","plt.ylim(0, 1)  # Sesuaikan dengan rentang akurasi (0-1)\n","plt.grid()\n","plt.show()"],"metadata":{"id":"VkmV2VKkbyuk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Implementasi"],"metadata":{"id":"iVelQPrPb9PP"}},{"cell_type":"code","source":["# teks = ['Jakarta - Makna motif adalah alasan atau penyebab seseorang melakukan sesuatu.',\n","#         'Ketika kita melakukan suatu tindakan pasti ada sesuatu hal yang mendorongnya.',\n","#         'Contohnya kita makan karena kita lapar.',\n","#         'Hal tersebut juga terjadi pada kegiatan ekonomi.',\n","#         'Semua kegiatan ekonomi tidak dapat terjadi begitu saja, namun terdapat suatu alasan atau penyebab yang mendorongnya.',\n","#         'Faktor pendorong inilah yang disebut motif ekonomi.',\n","#         'Baca artikel detikfinance, \"Pengertian Motif Ekonomi serta Tujuan, Sifat, Macam, dan Contohnya\" selengkapnya https://finance.detik.com/berita-ekonomi-bisnis/d-7048370/pengertian-motif-ekonomi-serta-tujuan-sifat-macam-dan-contohnya.',\n","#         'Download Apps Detikcom Sekarang https://apps.detik.com/detik/']\n","\n","# teks_lower = [kalimat.lower() for kalimat in teks]\n","\n","# print(teks_lower)\n"],"metadata":{"id":"zjsPh-R3Zp-o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========== data inputan ==========\n","new_data = str(input(\"masukkan data: \"))\n","\n","# ========== tokenizing kalimat ==========\n","new_data = sent_tokenize(new_data)\n","new_data = [kalimat.lower() for kalimat in new_data] #menjadikan lower\n","\n","# ========== vectorize ==========\n","inp_hasil_df_tf = []\n","\n","inp_termFreq_vectorizer = CountVectorizer()  #inisialisasi tfidf\n","inp_termFreq_matrix = inp_termFreq_vectorizer.fit_transform(new_data) #menjadikan tfidf setiap dokumen\n","\n","inp_terms = inp_termFreq_vectorizer.get_feature_names_out()\n","inp_tf_df = pd.DataFrame(inp_termFreq_matrix.toarray(), columns=inp_terms)\n","\n","inp_hasil_df_tf.append(inp_tf_df)\n"],"metadata":{"id":"Vy67TgXdb8g9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Jakarta - Makna motif adalah alasan atau penyebab seseorang melakukan sesuatu. Ketika kita melakukan suatu tindakan pasti ada sesuatu hal yang mendorongnya. Contohnya kita makan karena kita lapar. Hal tersebut juga terjadi pada kegiatan ekonomi. Semua kegiatan ekonomi tidak dapat terjadi begitu saja, namun terdapat suatu alasan atau penyebab yang mendorongnya. Faktor pendorong inilah yang disebut motif ekonomi.  Baca artikel detikfinance, \"Pengertian Motif Ekonomi serta Tujuan, Sifat, Macam, dan Contohnya\" selengkapnya https://finance.detik.com/berita-ekonomi-bisnis/d-7048370/pengertian-motif-ekonomi-serta-tujuan-sifat-macam-dan-contohnya.  Download Apps Detikcom Sekarang https://apps.detik.com/detik/"],"metadata":{"id":"LHFxh0AGcJAX"}},{"cell_type":"markdown","source":["JAKARTA, Indotimes.co.id â€“ Putri Zulkifli Hasan, anak dari Ketua Umum Partai Amanat Nasional (PAN) Zulkifli Hasan, tak punya itikad baik untuk menyelesaikan sengketa lahan yang menyeret namanya dengan cara mediasi.\n","\n","Dengan demikian, masalah sengketa tanah itu berlanjut dalam persidangan yang harus mendatangkan pihak-pihak beperkara.\n","\n","Sidang yang melibatkan Putri Zulkifli Hasan ini kembali digelar di Pengadilan Negeri Jakarta Timur (PN Jaktim), Kamis (9/11).\n","\n","Para pihak yang hadir, antara lain penggugat I Aziz Anugerah Yudha Prawira yang diwakili kuasa hukumnya dari Firma Hukum DR. Yayan Riyanto, SH, MH.\n","\n","Adapun tergugat yang hadir, yaitu Tergugat I Lie Andry Setyadarma yang diwakili pengacaranya dan Tergugat III Putri Zulkifli Hasan yang juga diwakili kuasa hukumnya, Andreas Tambunan.\n","\n","DR. Yayan Riyanto menyampaikan, gugatan yang diajukannya sudah dibacakan majelis hakim untuk kemudian dijawab para pihak tergugat."],"metadata":{"id":"vZTe9yxzzNbf"}},{"cell_type":"code","source":["# inp_hasil_df_tf"],"metadata":{"id":"W-csXPk4xHnt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========== co ocurence =======\n","inp_hasil_co_occurrence_df = []\n","inp_hasil_co_occurrence_matrix = []\n","\n","for i in range(len(inp_hasil_df_tf)):\n","\n","  # Membuat Co-occurrence Matrix\n","  inp_co_occurrence_matrix = np.dot(inp_hasil_df_tf[i].T,inp_hasil_df_tf[i])\n","\n","  # Mengganti diagonal dengan nol (karena kita tidak ingin memperhitungkan kata dengan dirinya sendiri)\n","  np.fill_diagonal(inp_co_occurrence_matrix, 0)\n","\n","  # mengambil columns\n","  inp_kolom = inp_hasil_df_tf[i].columns\n","\n","  # # Membuat DataFrame Co-occurrence\n","  inp_co_occurrence_df = pd.DataFrame(inp_co_occurrence_matrix, index=inp_kolom, columns=inp_kolom)\n","\n","  inp_hasil_co_occurrence_df.append(inp_co_occurrence_df)\n","  inp_hasil_co_occurrence_matrix.append(inp_co_occurrence_matrix)\n"],"metadata":{"id":"u_Fesz8HdWUu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inp_hasil_co_occurrence_df"],"metadata":{"id":"Vx9v6HnKdRlf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========== tambah graf dan atur treshold =======\n","inp_graf_results = []\n","treshold = 0\n","\n","for i in range(len(inp_hasil_co_occurrence_df)):\n","\n","  inp_graf = nx.Graph()  # Instantiate as a Graph object\n","\n","  inp_co_occurrence = inp_hasil_co_occurrence_df[i] #mengambil hasil coocurence per indeks yang disimpan array\n","  inp_koloms = inp_co_occurrence.columns #mengambil nama kolom saja dari coocurence array indeks\n","  inp_matrix_coocurrence = inp_hasil_co_occurrence_matrix[i] #mengambil matrix coocurencenya\n","\n","  for i_koloms in range(len(inp_koloms)): #perulangan setiap dari panjang kolom dari coocurence\n","      for j_koloms in range(i_koloms + 1, len(inp_koloms)): #perulangan dari setiap panjang kolom + 1, maksudna kolom indeks ke dua\n","\n","        inp_bobot = inp_matrix_coocurrence[i_koloms,j_koloms] #mencari bobot dengan setiap kolom\n","\n","        if inp_bobot > treshold: #cek bobot\n","          inp_graf.add_edge(inp_koloms[i_koloms], inp_koloms[j_koloms], weight=inp_matrix_coocurrence[i_koloms, j_koloms])\n","\n","  inp_graf_results.append(inp_graf)\n"],"metadata":{"id":"6fpj-JivczOr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==== centrality ===\n","inp_centrality_result = []\n","\n","for i in range(len(inp_graf_results)):\n","  inp_centrality = nx.pagerank(inp_graf_results[i]) #menjadikan graf setiap index list diclosness\n","\n","  inp_centrality_result.append(inp_centrality)\n","  # print(i)"],"metadata":{"id":"ThsPOknlcLuT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(inp_centrality_result)"],"metadata":{"id":"kIW8uNRQxbll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========= ranking ==========\n","inp_result_skor = []\n","\n","for sentences in new_data:\n","\n","  words = sentences.split()\n","  skor_kata = {}\n","\n","  for cek in words:\n","    if cek in inp_centrality_result[0]:\n","      skor_kata[cek] = inp_centrality_result[0][cek]\n","  inp_result_skor.append(skor_kata)\n"],"metadata":{"id":"qp2ylqUze7wy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(inp_result_skor)"],"metadata":{"id":"nOyrqjZUxZKV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# inp_result_skor"],"metadata":{"id":"0WUTqO0nYwz1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inp_result_bobot_kalimat = []\n","\n","for i in range(len(inp_result_skor)):\n","    current_bobot = {}\n","\n","    bobot_kalimat = sum(inp_result_skor[i].values())\n","    current_bobot[new_data[i]] = bobot_kalimat\n","\n","    inp_result_bobot_kalimat.append(current_bobot)\n"],"metadata":{"id":"UqIGDwaBfEls"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inp_result_bobot_kalimat"],"metadata":{"id":"_wfNpd36l_de"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["current_inp = []\n","inp_sorted_data = sorted(inp_result_bobot_kalimat, key=lambda x: list(x.values())[0], reverse=True)\n","\n","# ambil 5 data teratas\n","inp_sorted_data = inp_sorted_data[:5]\n","\n","final_inp = []\n","for hasil in inp_sorted_data:\n","  for key,values in hasil.items():\n","    final_inp.append(key)\n"],"metadata":{"id":"5XbDLXDzfSkZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# final_inp"],"metadata":{"id":"bPQB4ONTdIV4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_inp = \"\".join(final_inp)\n"],"metadata":{"id":"3gN0rmdXoJKu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === tfidf ===\n","\n","# Membuat final_inp menjadi list jika belum\n","if not isinstance(final_inp, list):\n","    final_inp = [final_inp]\n","\n","# Melakukan transformasi TF-IDF pada final_inp\n","rank_inp = summ_tfidf_vectorizer.transform(final_inp)\n","# rank_inp.toarray()\n"],"metadata":{"id":"J6F-bKWbfqGC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","z = str(input('masukkan kata : '))\n","\n","# === tfidf ===\n","\n","# Membuat z menjadi list jika belum\n","if not isinstance(z, list):\n","    z = [z]\n","\n","# Melakukan transformasi TF-IDF pada z\n","rank_z = summ_tfidf_vectorizer.transform(z)\n","# rank_inp.toarray()\n","\n","\n","predict_inp = knn.predict(rank_inp.toarray())\n","predict_inp"],"metadata":{"id":"eCJWIndtuHut"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test\n","\n","predict_inp = knn.predict(rank_inp.toarray())\n","predict_inp"],"metadata":{"id":"4ZcGDOMagB9m"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOjDA+sGbdq+df2BQs2puWU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}